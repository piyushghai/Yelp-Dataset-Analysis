{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import nltk #to preprocess and tokenize text data\n",
    "import string\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "\n",
    "#download english stopwords corpus\n",
    "nltk.download() \n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "POSITIVE_WORDS = set([line.strip() for line in open('positive-words.txt', 'r')])\n",
    "NEGATIVE_WORDS = set([line.strip() for line in open('negative-words.txt', 'r')])\n",
    "NLTK_STOPWORDS = set(stopwords.words('english'))\n",
    "MORE_STOPWORDS = set([line.strip() for line in open('more_stopwords.txt', 'r')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lcase_punct_tokenize(review):\n",
    "    review = review.lower()\n",
    "    reviews = review.translate(None, string.punctuation)\n",
    "    token_list = nltk.word_tokenize(review)\n",
    "    exclude_stopwords = lambda token : token not in NLTK_STOPWORDS\n",
    "    return filter(exclude_stopwords, token_list)\n",
    "\n",
    "def concat_preprocess_tokenize(review):\n",
    "    r = review.text.sum()\n",
    "    return lcase_punct_tokenize(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resto_review = pickle.load( open( \"resto_review_data.p\", \"rb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(list(resto_review.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = ['business_id', 'name', 'stars_review', 'text']\n",
    "df_features = resto_review[features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_find_ngram_counts_by_star_categories = df_features\n",
    "stars_vs_category_texts = df_find_ngram_counts_by_star_categories.groupby('stars_review').apply(concat_preprocess_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for stars in range(0, 1):\n",
    "    bigrams = [\"%s %s\" % bi for bi in nltk.bigrams(stars_vs_cat_texts[stars+1])]\n",
    "    bigrams_df = DataFrame.from_dict(Counter(bigrams).most_common(len(stars_vs_cat_texts[stars+1])))\n",
    "    bigrams_df.to_csv(str(stars+1) + '_bigrams_star.csv', index=False)\n",
    "    \n",
    "    trigrams = [\"%s %s %s\" % tri for tri in nltk.trigrams(stars_vs_cat_texts[stars+1])]\n",
    "    trigrams_df = DataFrame.from_dict(Counter(trigrams).most_common(len(stars_vs_cat_texts[stars+1])))\n",
    "    trigrams_df.to_csv(str(stars+1) + '_trigrams_star.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%R\n",
    "library(tm)\n",
    "library(wordcloud)\n",
    "library(RColorBrewer)\n",
    "\n",
    "palettes <- c(\"Reds\", \"Oranges\", \"Blues\", \"Purples\", \"Greens\")\n",
    "\n",
    "for (stars in 1:5) {\n",
    "    stars.bigrams.path <- paste(stars, '_bigrams_star.csv',sep='')\n",
    "    stars.trigrams.path <- paste(stars, '_trigrams_star.csv',sep='')\n",
    "    stars.bigrams.df <- read.csv(stars.bigrams.path)\n",
    "    stars.trigrams.df <- read.csv(stars.trigrams.path)\n",
    "    stars.wordcloud.df <- rbind(stars.bigrams.df[1:100,], stars.trigrams.df[1:100,])\n",
    "    stars.wordcloud.df <- stars.wordcloud.df[with(stars.wordcloud.df, order(-X1, X0)),]\n",
    "    \n",
    "    pal <- brewer.pal(9, palettes[stars])\n",
    "    pal <- pal[-(1:3)]\n",
    "    png(paste(stars, '_star_wordcloud.png',sep=''), width=960, height=960)\n",
    "    wordcloud(stars.wordcloud.df$X0, stars.wordcloud.df$X1 , max.words=200, colors=pal)\n",
    "    dev.off()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import Image\n",
    "Image(filename='1_star_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='2_star_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='3_star_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='4_star_wordcloud.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Image(filename='5_star_wordcloud.png')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
