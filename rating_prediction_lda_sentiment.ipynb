{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types\n",
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "    \n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for IPython Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "    \n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "        \n",
    "        print (\"importing notebook from %s\" % path)\n",
    "                                       \n",
    "        # load the notebook object\n",
    "        nb = nbformat.read(path, as_version=4)\n",
    "        \n",
    "        \n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "        \n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "        \n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates IPython Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "    \n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "        \n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "        \n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rating_prediction_lda import totalTopics,all_text_train, all_text_test,topic_dist_train_all_stars,topic_dist_test_all_stars\n",
    "from rating_prediction_tfidf import tfidfvectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getSentiment(s):\n",
    "    if s < 3.5:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_train_all_stars['Sentiment'] = topic_dist_train_all_stars['Star'].map(getSentiment)\n",
    "topic_dist_test_all_stars['Sentiment'] = topic_dist_test_all_stars['Star'].map(getSentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentimentTextTrain = tfidfvectorizer.fit_transform(all_text_train)\n",
    "sentimentTextTest = tfidfvectorizer.transform(all_text_test)\n",
    "\n",
    "sentimentLabelTrain = topic_dist_train_all_stars['Sentiment']\n",
    "sentimentLabelTest = topic_dist_test_all_stars['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = LogisticRegression().fit(sentimentTextTrain, sentimentLabelTrain)\n",
    "\n",
    "ySentimentTrain = classifier.predict(sentimentTextTrain)\n",
    "ySentimentTest = classifier.predict(sentimentTextTest)\n",
    "\n",
    "topic_dist_train_all_stars['Sentiment_Predicted'] = ySentimentTrain\n",
    "topic_dist_test_all_stars['Sentiment_Predicted'] = ySentimentTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = list(topic_dist_train_all_stars.columns[:totalTopics])\n",
    "features.append(topic_dist_train_all_stars.columns[totalTopics+2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = topic_dist_train_all_stars[features]\n",
    "y_train = topic_dist_train_all_stars['Star']\n",
    "\n",
    "x_test = topic_dist_test_all_stars[features]\n",
    "y_test = topic_dist_test_all_stars['Star'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifiers = [MultinomialNB(), LogisticRegression(), RandomForestClassifier(n_estimators=100, n_jobs=2), AdaBoostClassifier(n_estimators=100)]\n",
    "classifiers_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Random Forest', 'AdaBoost']\n",
    "\n",
    "LdaSentimentResults = {}\n",
    "for (i, clf_) in enumerate(classifiers):\n",
    "    clf = clf_.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    \n",
    "    precision = metrics.precision_score(y_test, preds)\n",
    "    recall = metrics.recall_score(y_test, preds)\n",
    "    f1 = metrics.f1_score(y_test, preds)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds)\n",
    "    matrix = metrics.confusion_matrix(y_test, preds, labels=starsGroup.groups.keys())\n",
    "    \n",
    "    data = {'precision':precision,\n",
    "            'recall':recall,\n",
    "            'f1_score':f1,\n",
    "            'accuracy':accuracy,\n",
    "            'clf_report':report,\n",
    "            'clf_matrix':matrix,\n",
    "            'y_predicted':preds}\n",
    "    \n",
    "    LdaSentimentResults[classifiers_names[i]] = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
    "pd.DataFrame(LdaSentimentResults).T[cols].T\n",
    "\n",
    "for model, val in LdaSentimentResults.iteritems():\n",
    "    print '-------'+'-'*len(model)\n",
    "    print 'MODEL:', model\n",
    "    print '-------'+'-'*len(model)\n",
    "    print 'The precision for this classifier is ' + str(val['precision'])\n",
    "    print 'The recall for this classifier is    ' + str(val['recall'])\n",
    "    print 'The f1 for this classifier is        ' + str(val['f1_score'])\n",
    "    print 'The accuracy for this classifier is  ' + str(val['accuracy'])\n",
    "    print 'The confusion matrix for this classifier is  \\n' + str(val['clf_matrix'])\n",
    "    print '\\nHere is the classification report:'\n",
    "    print val['clf_report']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
