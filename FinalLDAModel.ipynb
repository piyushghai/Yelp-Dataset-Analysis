{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:840: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#All the imports in one place\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import re\n",
    "import scipy as sp\n",
    "import seaborn\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import *\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, classification_report, precision_score, recall_score, roc_auc_score\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from collections import Counter\n",
    "import os\n",
    "import sys\n",
    "#reload(sys)\n",
    "#sys.setdefaultencoding(\"utf-8\")\n",
    "\n",
    "\n",
    "plt.rc('figure', figsize=(10,6))\n",
    "seaborn.set()\n",
    "colors = seaborn.color_palette()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create the LDA model from the training dataset.\n",
    "def perform_lda(train, totalTopics):\n",
    "    corpus = []\n",
    "    for text in train:\n",
    "        text_list = [word for word in text]\n",
    "        try:\n",
    "            corpus.append(text_list)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Build dictionary\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    # Save the dictionary\n",
    "    dictionary.save('restaurant_reviews.dict')\n",
    "        \n",
    "    # Build vectorized corpus\n",
    "    corpus_vector = [dictionary.doc2bow(text) for text in corpus]\n",
    "    \n",
    "    lda = models.LdaModel(corpus_vector, num_topics=totalTopics, id2word=dictionary)\n",
    "    return lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generates a matrix of topic probabilities for each document in matrix\n",
    "# Returns topic_dist for the input corpus, and all_dist, a running sum of all the corpuses\n",
    "def getTopicDistMatrix(lda, totalTopics, corpus, all_dist, star):\n",
    "    topic_dist = [0] * totalTopics\n",
    "    # Load the dictionary\n",
    "    dictionary = corpora.Dictionary.load(\"restaurant_reviews.dict\")\n",
    "    # For every reviewDoc in the corpus, compute the prob dist matrix for each term\n",
    "    for review in corpus:\n",
    "        vec = dictionary.doc2bow(review.lower().split())\n",
    "        output = lda[vec]\n",
    "        highest_prob = 0\n",
    "        highest_topic = 0\n",
    "        temp = [0] * totalTopics    # List to keep track of topic distribution for each document\n",
    "        for topic in output:\n",
    "            this_topic, this_prob = topic\n",
    "            temp[this_topic] = this_prob\n",
    "            if this_prob > highest_prob:\n",
    "                highest_prob = this_prob \n",
    "                highest_topic = this_topic\n",
    "        temp.append(star)\n",
    "        all_dist.append(temp)\n",
    "        topic_dist[highest_topic] += 1\n",
    "    return topic_dist, all_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "all_text_train = pickle.load (open(\"all_text_train.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corpus_5stars_train = pickle.load (open(\"corpus_5stars_train.p\", \"rb\"))\n",
    "corpus_4stars_train = pickle.load (open(\"corpus_4stars_train.p\", \"rb\"))\n",
    "corpus_3stars_train = pickle.load (open(\"corpus_3stars_train.p\", \"rb\"))\n",
    "corpus_2stars_train = pickle.load (open(\"corpus_2stars_train.p\", \"rb\"))\n",
    "corpus_1stars_train = pickle.load (open(\"corpus_1stars_train.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%time lda = perform_lda(all_text_train, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_list = []\n",
    "\n",
    "# Keep a separate list to count topics\n",
    "topic_dist_5stars = []\n",
    "topic_dist_4stars = []\n",
    "topic_dist_3stars = []\n",
    "topic_dist_2stars = []\n",
    "topic_dist_1stars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "totalTopics = 15\n",
    "topic_dist_5stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_5stars_train, topic_dist_list, 5)\n",
    "topic_dist_4stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_4stars_train, topic_dist_list, 4)\n",
    "topic_dist_3stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_3stars_train, topic_dist_list, 3)\n",
    "topic_dist_2stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_2stars_train, topic_dist_list, 2)\n",
    "topic_dist_1stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_1stars_train, topic_dist_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in xrange(1, totalTopics+1):\n",
    "    cols.append(\"Topic\"+ str(i))\n",
    "cols.append(\"Star\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_dist_train_all_stars = pd.DataFrame(topic_dist_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_text_test = pickle.load (open(\"all_text_test.p\", \"rb\"))\n",
    "corpus_5stars_test = pickle.load (open(\"corpus_5stars_test.p\", \"rb\"))\n",
    "corpus_4stars_test = pickle.load (open(\"corpus_4stars_test.p\", \"rb\"))\n",
    "corpus_3stars_test = pickle.load (open(\"corpus_3stars_test.p\", \"rb\"))\n",
    "corpus_2stars_test = pickle.load (open(\"corpus_2stars_test.p\", \"rb\"))\n",
    "corpus_1stars_test = pickle.load (open(\"corpus_1stars_test.p\", \"rb\"))\n",
    "\n",
    "starsGroup = pickle.load (open(\"starsGroup.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_list = []\n",
    "\n",
    "# Keep a separate list to count topics\n",
    "topic_dist_5stars = []\n",
    "topic_dist_4stars = []\n",
    "topic_dist_3stars = []\n",
    "topic_dist_2stars = []\n",
    "topic_dist_1stars = []\n",
    "\n",
    "\n",
    "topic_dist_5stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_5stars_test, topic_dist_list, 5)\n",
    "topic_dist_4stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_4stars_test, topic_dist_list, 4)\n",
    "topic_dist_3stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_3stars_test, topic_dist_list, 3)\n",
    "topic_dist_2stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_2stars_test, topic_dist_list, 2)\n",
    "topic_dist_1stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_1stars_test, topic_dist_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in xrange(1, totalTopics+1):\n",
    "    cols.append(\"Topic\"+ str(i))\n",
    "cols.append(\"Star\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_test_all_stars = pd.DataFrame(topic_dist_list, columns=cols)\n",
    "\n",
    "features = list(topic_dist_train_all_stars.columns[:totalTopics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = topic_dist_train_all_stars[features]\n",
    "y_train = topic_dist_train_all_stars['Star']\n",
    "\n",
    "x_test = topic_dist_test_all_stars[features]\n",
    "y_test = topic_dist_test_all_stars['Star'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "C:\\Users\\Karan\\Anaconda2\\lib\\site-packages\\sklearn\\metrics\\classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.201363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.277985</td>\n",
       "      <td>0.277985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "      <td>0.448735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AdaBoost Logistic Regression Multinomial Naive Bayes  \\\n",
       "precision  0.201363            0.201363                0.201363   \n",
       "recall     0.448735            0.448735                0.448735   \n",
       "f1_score   0.277985            0.277985                0.277985   \n",
       "accuracy   0.448735            0.448735                0.448735   \n",
       "\n",
       "          Nearest Neighbors Random Forest  \n",
       "precision          0.201363      0.201363  \n",
       "recall             0.448735      0.448735  \n",
       "f1_score           0.277985      0.277985  \n",
       "accuracy           0.448735      0.448735  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = [MultinomialNB(), LogisticRegression(), RandomForestClassifier(n_estimators=100, n_jobs=2), AdaBoostClassifier(n_estimators=100)]\n",
    "clf_names = ['Multinomial Naive Bayes', 'Logistic Regression', 'Random Forest', 'AdaBoost']\n",
    "\n",
    "LDAResults = {}\n",
    "for (i, clf_) in enumerate(clfs):\n",
    "    clf = clf_.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    \n",
    "    precision = metrics.precision_score(y_test, preds)\n",
    "    recall = metrics.recall_score(y_test, preds)\n",
    "    f1 = metrics.f1_score(y_test, preds)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds)\n",
    "    matrix = metrics.confusion_matrix(y_test, preds, labels=starsGroup.groups.keys())\n",
    "    \n",
    "    data = {'precision':precision,\n",
    "            'recall':recall,\n",
    "            'f1_score':f1,\n",
    "            'accuracy':accuracy,\n",
    "            'clf_report':report,\n",
    "            'clf_matrix':matrix,\n",
    "            'y_predicted':preds}\n",
    "    \n",
    "    LDAResults[clf_names[i]] = data\n",
    "\n",
    "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
    "LDA_Prediction_Perf = pd.DataFrame(LDAResults).T[cols].T\n",
    "LDA_Prediction_Perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.stdout = open(\"lda_results.txt\", 'a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for model, val in LDAResults.iteritems():\n",
    "    print ('-------'+'-'*len(model))\n",
    "    print 'MODEL:', model\n",
    "    print ('-------'+'-'*len(model))\n",
    "    print ('The precision for this classifier is ' + str(val['precision']))\n",
    "    print ('The recall for this classifier is    ' + str(val['recall']))\n",
    "    print ('The f1 for this classifier is        ' + str(val['f1_score']))\n",
    "    print ('The accuracy for this classifier is  ' + str(val['accuracy']))\n",
    "    print ('The confusion matrix for this classifier is  \\n' + str(val['clf_matrix']))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
