{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import io, os, sys, types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from IPython import get_ipython\n",
    "from nbformat import read\n",
    "from IPython.core.interactiveshell import InteractiveShell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_notebook(fullname, path=None):\n",
    "    \"\"\"find a notebook, given its fully qualified name and an optional path\n",
    "    \n",
    "    This turns \"foo.bar\" into \"foo/bar.ipynb\"\n",
    "    and tries turning \"Foo_Bar\" into \"Foo Bar\" if Foo_Bar\n",
    "    does not exist.\n",
    "    \"\"\"\n",
    "    name = fullname.rsplit('.', 1)[-1]\n",
    "    if not path:\n",
    "        path = ['']\n",
    "    for d in path:\n",
    "        nb_path = os.path.join(d, name + \".ipynb\")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path\n",
    "        # let import Notebook_Name find \"Notebook Name.ipynb\"\n",
    "        nb_path = nb_path.replace(\"_\", \" \")\n",
    "        if os.path.isfile(nb_path):\n",
    "            return nb_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookLoader(object):\n",
    "    \"\"\"Module Loader for IPython Notebooks\"\"\"\n",
    "    def __init__(self, path=None):\n",
    "        self.shell = InteractiveShell.instance()\n",
    "        self.path = path\n",
    "    \n",
    "    def load_module(self, fullname):\n",
    "        \"\"\"import a notebook as a module\"\"\"\n",
    "        path = find_notebook(fullname, self.path)\n",
    "        \n",
    "        print (\"importing notebook from %s\" % path)\n",
    "                                       \n",
    "        # load the notebook object\n",
    "        nb = nbformat.read(path, as_version=4)\n",
    "        \n",
    "        \n",
    "        # create the module and add it to sys.modules\n",
    "        # if name in sys.modules:\n",
    "        #    return sys.modules[name]\n",
    "        mod = types.ModuleType(fullname)\n",
    "        mod.__file__ = path\n",
    "        mod.__loader__ = self\n",
    "        mod.__dict__['get_ipython'] = get_ipython\n",
    "        sys.modules[fullname] = mod\n",
    "        \n",
    "        # extra work to ensure that magics that would affect the user_ns\n",
    "        # actually affect the notebook module's ns\n",
    "        save_user_ns = self.shell.user_ns\n",
    "        self.shell.user_ns = mod.__dict__\n",
    "        \n",
    "        try:\n",
    "          for cell in nb.cells:\n",
    "            if cell.cell_type == 'code':\n",
    "                # transform the input to executable Python\n",
    "                code = self.shell.input_transformer_manager.transform_cell(cell.source)\n",
    "                # run the code in themodule\n",
    "                exec(code, mod.__dict__)\n",
    "        finally:\n",
    "            self.shell.user_ns = save_user_ns\n",
    "        return mod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class NotebookFinder(object):\n",
    "    \"\"\"Module finder that locates IPython Notebooks\"\"\"\n",
    "    def __init__(self):\n",
    "        self.loaders = {}\n",
    "    \n",
    "    def find_module(self, fullname, path=None):\n",
    "        nb_path = find_notebook(fullname, path)\n",
    "        if not nb_path:\n",
    "            return\n",
    "        \n",
    "        key = path\n",
    "        if path:\n",
    "            # lists aren't hashable\n",
    "            key = os.path.sep.join(path)\n",
    "        \n",
    "        if key not in self.loaders:\n",
    "            self.loaders[key] = NotebookLoader(path)\n",
    "        return self.loaders[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.meta_path.append(NotebookFinder())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "importing notebook from pre_processing.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAHxCAYAAACWH4HKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAgAFCMwAAAGCA0AwAAAAY+B+mPwwnzxSWkQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b321d890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pre_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean all the reviews by removing stop words as well as punctutation marks\n",
    "def process_reviews(data_set):\n",
    "    clean_data_set = []\n",
    "    for text in data_set:\n",
    "        # Remove punctuations\n",
    "        text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "        # To lowercase\n",
    "        text = text.lower()\n",
    "        # Remove stop words\n",
    "        texts = [word for word in text.split() if word not in stop_words_set]\n",
    "        try:\n",
    "            clean_data_set.append(' '.join(texts))\n",
    "        except:\n",
    "            pass\n",
    "    return clean_data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to create the LDA model from the training dataset.\n",
    "def perform_lda(train, totalTopics):\n",
    "    corpus = []\n",
    "    for text in train:\n",
    "        # Remove punctuations\n",
    "        text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
    "        # To lowercase\n",
    "        text = text.lower()\n",
    "        # Remove stop words\n",
    "        texts = [word for word in text.lower().split() if word not in stop_words_set]\n",
    "        try:\n",
    "            corpus.append(texts)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    # Build dictionary\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    dictionary.save('restaurant_reviews.dict')\n",
    "        \n",
    "    # Build vectorized corpus\n",
    "    corpus_vector = [dictionary.doc2bow(text) for text in corpus]\n",
    "    \n",
    "    lda = models.LdaModel(corpus_vector, num_topics=totalTopics, id2word=dictionary)\n",
    "    return lda\n",
    "\n",
    "# Generates a matrix of topic probabilities for each document in matrix\n",
    "# Returns topic_dist for the input corpus, and all_dist, a running sum of all the corpuses\n",
    "def getTopicDistMatrix(lda, totalTopics, corpus, all_dist, star):\n",
    "    topic_dist = [0] * totalTopics\n",
    "    # Load the dictionary\n",
    "    dictionary = corpora.Dictionary.load(\"restaurant_reviews.dict\")\n",
    "    # For every reviewDoc in the corpus, compute the prob dist matrix for each term\n",
    "    for review in corpus:\n",
    "        vec = dictionary.doc2bow(review.lower().split())\n",
    "        output = lda[vec]\n",
    "        highest_prob = 0\n",
    "        highest_topic = 0\n",
    "        temp = [0] * totalTopics    # List to keep track of topic distribution for each document\n",
    "        for topic in output:\n",
    "            this_topic, this_prob = topic\n",
    "            temp[this_topic] = this_prob\n",
    "            if this_prob > highest_prob:\n",
    "                highest_prob = this_prob \n",
    "                highest_topic = this_topic\n",
    "        temp.append(star)\n",
    "        all_dist.append(temp)\n",
    "        topic_dist[highest_topic] += 1\n",
    "    return topic_dist, all_dist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "import cPickle as pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import re\n",
    "import scipy as sp\n",
    "import seaborn\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.lda import LDA\n",
    "from sklearn.qda import QDA\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#Set of English language Stop Words from the dictionary\n",
    "stop_words_set = set(stopwords.words(\"english\"))\n",
    "\n",
    "totalTopics = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from pre_processing import review_data as resto_review\n",
    "# Group all reviews per star rating and extract text out of them\n",
    "starsGroup = resto_review.groupby('stars_review')\n",
    "\n",
    "text_star_1 = starsGroup.get_group(1.0)['text']\n",
    "text_star_2 = starsGroup.get_group(2.0)['text']\n",
    "text_star_3 = starsGroup.get_group(3.0)['text']\n",
    "text_star_4 = starsGroup.get_group(4.0)['text']\n",
    "text_star_5 = starsGroup.get_group(5.0)['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optional : To reduce the dataset size and prevent laptop from frying, reduce the dataset size by sampling\n",
    "sampling = 30000 # No of rows to be sampled\n",
    "\n",
    "text_star_1 = text_star_1.sample(sampling)\n",
    "text_star_2 = text_star_2.sample(sampling)\n",
    "text_star_3 = text_star_3.sample(sampling)\n",
    "text_star_4 = text_star_4.sample(sampling)\n",
    "text_star_5 = text_star_5.sample(sampling)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_star_1 = [1.0]*len(text_star_1)\n",
    "label_star_2 = [2.0]*len(text_star_2)\n",
    "label_star_3 = [3.0]*len(text_star_3)\n",
    "label_star_4 = [4.0]*len(text_star_4)\n",
    "label_star_5 = [5.0]*len(text_star_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Create test and training dataset. We use 80-20 sampling here. We can use 66-33 sampling too\n",
    "train_stars_1, test_stars_1, train_labels_stars_1, all_1stars_labels_test = train_test_split(text_star_1, label_star_1, test_size=0.30)\n",
    "train_stars_2, test_stars_2, train_labels_stars_2, all_2stars_labels_test = train_test_split(text_star_2, label_star_2, test_size=0.30)\n",
    "train_stars_3, test_stars_3, train_labels_stars_3, all_3stars_labels_test = train_test_split(text_star_3, label_star_3, test_size=0.30)\n",
    "train_stars_4, test_stars_4, train_labels_stars_4, all_4stars_labels_test = train_test_split(text_star_4, label_star_4, test_size=0.30)\n",
    "train_stars_5, test_stars_5, train_labels_stars_5, all_5stars_labels_test = train_test_split(text_star_5, label_star_5, test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21000\n"
     ]
    }
   ],
   "source": [
    "print(len(train_labels_stars_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Cleaning all the reviews and building corpus out of them\n",
    "corpus_5stars = process_reviews(train_stars_5)\n",
    "corpus_4stars = process_reviews(train_stars_4)\n",
    "corpus_3stars = process_reviews(train_stars_3)\n",
    "corpus_2stars = process_reviews(train_stars_2)\n",
    "corpus_1stars = process_reviews(train_stars_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 5-star reviews after processing:  21000\n",
      "Number of 4-star reviews after processing:  21000\n",
      "Number of 3-star reviews after processing:  21000\n",
      "Number of 2-star reviews after processing:  21000\n",
      "Number of 1-star reviews after processing:  21000\n"
     ]
    }
   ],
   "source": [
    "print \"Number of 5-star reviews after processing: \", len(corpus_5stars)\n",
    "print \"Number of 4-star reviews after processing: \", len(corpus_4stars)\n",
    "print \"Number of 3-star reviews after processing: \", len(corpus_3stars)\n",
    "print \"Number of 2-star reviews after processing: \", len(corpus_2stars)\n",
    "print \"Number of 1-star reviews after processing: \", len(corpus_1stars)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creating combined dataset for training, containing representation of all the 5 star ratings possible\n",
    "all_5_4_train = np.append(corpus_5stars, corpus_4stars)\n",
    "all_5_4_3_train = np.append(all_5_4_train, corpus_3stars)\n",
    "all_5_4_3_2_train = np.append(all_5_4_3_train, corpus_2stars)\n",
    "all_text_train = np.append(all_5_4_3_2_train, corpus_1stars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 58s, sys: 4.34 s, total: 5min 3s\n",
      "Wall time: 5min 7s\n"
     ]
    }
   ],
   "source": [
    "# Building the LDA model\n",
    "%time lda = perform_lda(all_text_train, totalTopics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_list = []\n",
    "\n",
    "# Keep a separate list to count topics\n",
    "topic_dist_5stars = []\n",
    "topic_dist_4stars = []\n",
    "topic_dist_3stars = []\n",
    "topic_dist_2stars = []\n",
    "topic_dist_1stars = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_5stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_5stars, topic_dist_list, 5)\n",
    "topic_dist_4stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_4stars, topic_dist_list, 4)\n",
    "topic_dist_3stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_3stars, topic_dist_list, 3)\n",
    "topic_dist_2stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_2stars, topic_dist_list, 2)\n",
    "topic_dist_1stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_1stars, topic_dist_list, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in xrange(1, totalTopics+1):\n",
    "    cols.append(\"Topic\"+ str(i))\n",
    "cols.append(\"Star\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_train_all_stars = pd.DataFrame(topic_dist_list, columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 5-star reviews after processing:  9000\n",
      "Number of 4-star reviews after processing:  9000\n",
      "Number of 3-star reviews after processing:  9000\n",
      "Number of 2-star reviews after processing:  9000\n",
      "Number of 1-star reviews after processing:  9000\n"
     ]
    }
   ],
   "source": [
    "corpus_5stars_test = process_reviews(test_stars_5)\n",
    "corpus_4stars_test = process_reviews(test_stars_4)\n",
    "corpus_3stars_test = process_reviews(test_stars_3)\n",
    "corpus_2stars_test = process_reviews(test_stars_2)\n",
    "corpus_1stars_test = process_reviews(test_stars_1)\n",
    "\n",
    "print \"Number of 5-star reviews after processing: \", len(corpus_5stars_test)\n",
    "print \"Number of 4-star reviews after processing: \", len(corpus_4stars_test)\n",
    "print \"Number of 3-star reviews after processing: \", len(corpus_3stars_test)\n",
    "print \"Number of 2-star reviews after processing: \", len(corpus_2stars_test)\n",
    "print \"Number of 1-star reviews after processing: \", len(corpus_1stars_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_5_4_test = np.append(corpus_5stars_test, corpus_4stars_test)\n",
    "all_5_4_3_test = np.append(all_5_4_test, corpus_3stars_test)\n",
    "all_5_4_3_2_test = np.append(all_5_4_3_test, corpus_2stars_test)\n",
    "all_text_test = np.append(all_5_4_3_2_test, corpus_1stars_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_list = []\n",
    "\n",
    "# Keep a separate list to count topics\n",
    "topic_dist_5stars = []\n",
    "topic_dist_4stars = []\n",
    "topic_dist_3stars = []\n",
    "topic_dist_2stars = []\n",
    "topic_dist_1stars = []\n",
    "\n",
    "\n",
    "topic_dist_5stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_5stars_test, topic_dist_list, 5)\n",
    "topic_dist_4stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_4stars_test, topic_dist_list, 4)\n",
    "topic_dist_3stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_3stars_test, topic_dist_list, 3)\n",
    "topic_dist_2stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_2stars_test, topic_dist_list, 2)\n",
    "topic_dist_1stars, topic_dist_list = getTopicDistMatrix(lda, totalTopics, corpus_1stars_test, topic_dist_list, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = []\n",
    "for i in xrange(1, totalTopics+1):\n",
    "    cols.append(\"Topic\"+ str(i))\n",
    "cols.append(\"Star\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_dist_test_all_stars = pd.DataFrame(topic_dist_list, columns=cols)\n",
    "\n",
    "features = list(topic_dist_train_all_stars.columns[:totalTopics])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = topic_dist_train_all_stars[features]\n",
    "y_train = topic_dist_train_all_stars['Star']\n",
    "\n",
    "x_test = topic_dist_test_all_stars[features]\n",
    "y_test = topic_dist_test_all_stars['Star'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1203: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:1304: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n",
      "/Users/piyushghai/anaconda/lib/python2.7/site-packages/sklearn/metrics/classification.py:756: DeprecationWarning: The default `weighted` averaging is deprecated, and from version 0.18, use of precision, recall or F-score with multiclass or multilabel data or pos_label=None will result in an exception. Please set an explicit value for `average`, one of (None, 'micro', 'macro', 'weighted', 'samples'). In cross validation use, for instance, scoring=\"f1_weighted\" instead of scoring=\"f1\".\n",
      "  sample_weight=sample_weight)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>Logistic Regression</th>\n",
       "      <th>Multinomial Naive Bayes</th>\n",
       "      <th>Nearest Neighbors</th>\n",
       "      <th>Random Forest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>precision</th>\n",
       "      <td>0.328119</td>\n",
       "      <td>0.320558</td>\n",
       "      <td>0.321637</td>\n",
       "      <td>0.281038</td>\n",
       "      <td>0.313159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>recall</th>\n",
       "      <td>0.342089</td>\n",
       "      <td>0.341178</td>\n",
       "      <td>0.338511</td>\n",
       "      <td>0.286244</td>\n",
       "      <td>0.320022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f1_score</th>\n",
       "      <td>0.330258</td>\n",
       "      <td>0.322069</td>\n",
       "      <td>0.324179</td>\n",
       "      <td>0.279558</td>\n",
       "      <td>0.315531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.342089</td>\n",
       "      <td>0.341178</td>\n",
       "      <td>0.338511</td>\n",
       "      <td>0.286244</td>\n",
       "      <td>0.320022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           AdaBoost Logistic Regression Multinomial Naive Bayes  \\\n",
       "precision  0.328119            0.320558                0.321637   \n",
       "recall     0.342089            0.341178                0.338511   \n",
       "f1_score   0.330258            0.322069                0.324179   \n",
       "accuracy   0.342089            0.341178                0.338511   \n",
       "\n",
       "          Nearest Neighbors Random Forest  \n",
       "precision          0.281038      0.313159  \n",
       "recall             0.286244      0.320022  \n",
       "f1_score           0.279558      0.315531  \n",
       "accuracy           0.286244      0.320022  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs = [KNeighborsClassifier(), MultinomialNB(), LogisticRegression(), RandomForestClassifier(n_estimators=100, n_jobs=2), AdaBoostClassifier(n_estimators=100)]\n",
    "clf_names = ['Nearest Neighbors', 'Multinomial Naive Bayes', 'Logistic Regression', 'Random Forest', 'AdaBoost']\n",
    "\n",
    "LDAResults = {}\n",
    "for (i, clf_) in enumerate(clfs):\n",
    "    clf = clf_.fit(x_train, y_train)\n",
    "    preds = clf.predict(x_test)\n",
    "    \n",
    "    precision = metrics.precision_score(y_test, preds)\n",
    "    recall = metrics.recall_score(y_test, preds)\n",
    "    f1 = metrics.f1_score(y_test, preds)\n",
    "    accuracy = accuracy_score(y_test, preds)\n",
    "    report = classification_report(y_test, preds)\n",
    "    matrix = metrics.confusion_matrix(y_test, preds, labels=starsGroup.groups.keys())\n",
    "    \n",
    "    data = {'precision':precision,\n",
    "            'recall':recall,\n",
    "            'f1_score':f1,\n",
    "            'accuracy':accuracy,\n",
    "            'clf_report':report,\n",
    "            'clf_matrix':matrix,\n",
    "            'y_predicted':preds}\n",
    "    \n",
    "    LDAResults[clf_names[i]] = data\n",
    "\n",
    "cols = ['precision', 'recall', 'f1_score', 'accuracy']\n",
    "LDA_Prediction_Perf = pd.DataFrame(LDAResults).T[cols].T\n",
    "LDA_Prediction_Perf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------\n",
      "MODEL: Random Forest\n",
      "--------------------\n",
      "The precision for this classifier is 0.313159423717\n",
      "The recall for this classifier is    0.320022222222\n",
      "The f1 for this classifier is        0.315531178935\n",
      "The accuracy for this classifier is  0.320022222222\n",
      "The confusion matrix for this classifier is  \n",
      "[[4771 1788  993  693  755]\n",
      " [2748 2160 1636 1306 1150]\n",
      " [1493 1794 2096 1983 1634]\n",
      " [ 936 1327 2059 2481 2197]\n",
      " [ 919 1144 1561 2483 2893]]\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.53      0.48      9000\n",
      "          2       0.26      0.24      0.25      9000\n",
      "          3       0.25      0.23      0.24      9000\n",
      "          4       0.28      0.28      0.28      9000\n",
      "          5       0.34      0.32      0.33      9000\n",
      "\n",
      "avg / total       0.31      0.32      0.32     45000\n",
      "\n",
      "---------------\n",
      "MODEL: AdaBoost\n",
      "---------------\n",
      "The precision for this classifier is 0.328118902246\n",
      "The recall for this classifier is    0.342088888889\n",
      "The f1 for this classifier is        0.330257905228\n",
      "The accuracy for this classifier is  0.342088888889\n",
      "The confusion matrix for this classifier is  \n",
      "[[5245 1505  846  472  932]\n",
      " [2923 2033 1488 1108 1448]\n",
      " [1526 1667 1862 1753 2192]\n",
      " [ 992 1169 1584 2214 3041]\n",
      " [ 967  937 1128 1928 4040]]\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.45      0.58      0.51      9000\n",
      "          2       0.28      0.23      0.25      9000\n",
      "          3       0.27      0.21      0.23      9000\n",
      "          4       0.30      0.25      0.27      9000\n",
      "          5       0.35      0.45      0.39      9000\n",
      "\n",
      "avg / total       0.33      0.34      0.33     45000\n",
      "\n",
      "--------------------------\n",
      "MODEL: Logistic Regression\n",
      "--------------------------\n",
      "The precision for this classifier is 0.320557683249\n",
      "The recall for this classifier is    0.341177777778\n",
      "The f1 for this classifier is        0.322068943731\n",
      "The accuracy for this classifier is  0.341177777778\n",
      "The confusion matrix for this classifier is  \n",
      "[[5781 1049  898  496  776]\n",
      " [3490 1545 1530 1077 1358]\n",
      " [1902 1395 1833 1709 2161]\n",
      " [1174 1040 1595 2078 3113]\n",
      " [1119  868 1216 1681 4116]]\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.43      0.64      0.51      9000\n",
      "          2       0.26      0.17      0.21      9000\n",
      "          3       0.26      0.20      0.23      9000\n",
      "          4       0.30      0.23      0.26      9000\n",
      "          5       0.36      0.46      0.40      9000\n",
      "\n",
      "avg / total       0.32      0.34      0.32     45000\n",
      "\n",
      "------------------------\n",
      "MODEL: Nearest Neighbors\n",
      "------------------------\n",
      "The precision for this classifier is 0.281038121834\n",
      "The recall for this classifier is    0.286244444444\n",
      "The f1 for this classifier is        0.279557771661\n",
      "The accuracy for this classifier is  0.286244444444\n",
      "The confusion matrix for this classifier is  \n",
      "[[4609 2079 1038  700  574]\n",
      " [3182 2130 1587 1216  885]\n",
      " [1978 1995 1956 1794 1277]\n",
      " [1436 1651 2105 2128 1680]\n",
      " [1385 1483 1853 2221 2058]]\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.37      0.51      0.43      9000\n",
      "          2       0.23      0.24      0.23      9000\n",
      "          3       0.23      0.22      0.22      9000\n",
      "          4       0.26      0.24      0.25      9000\n",
      "          5       0.32      0.23      0.27      9000\n",
      "\n",
      "avg / total       0.28      0.29      0.28     45000\n",
      "\n",
      "------------------------------\n",
      "MODEL: Multinomial Naive Bayes\n",
      "------------------------------\n",
      "The precision for this classifier is 0.321636551923\n",
      "The recall for this classifier is    0.338511111111\n",
      "The f1 for this classifier is        0.324179076565\n",
      "The accuracy for this classifier is  0.338511111111\n",
      "The confusion matrix for this classifier is  \n",
      "[[5538 1422  968  415  657]\n",
      " [3231 1912 1673  926 1258]\n",
      " [1696 1678 1972 1540 2114]\n",
      " [1037 1324 1690 1866 3083]\n",
      " [1018 1106 1317 1614 3945]]\n",
      "\n",
      "Here is the classification report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.44      0.62      0.51      9000\n",
      "          2       0.26      0.21      0.23      9000\n",
      "          3       0.26      0.22      0.24      9000\n",
      "          4       0.29      0.21      0.24      9000\n",
      "          5       0.36      0.44      0.39      9000\n",
      "\n",
      "avg / total       0.32      0.34      0.32     45000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for model, val in LDAResults.iteritems():\n",
    "    print '-------'+'-'*len(model)\n",
    "    print 'MODEL:', model\n",
    "    print '-------'+'-'*len(model)\n",
    "    print 'The precision for this classifier is ' + str(val['precision'])\n",
    "    print 'The recall for this classifier is    ' + str(val['recall'])\n",
    "    print 'The f1 for this classifier is        ' + str(val['f1_score'])\n",
    "    print 'The accuracy for this classifier is  ' + str(val['accuracy'])\n",
    "    print 'The confusion matrix for this classifier is  \\n' + str(val['clf_matrix'])\n",
    "    print '\\nHere is the classification report:'\n",
    "    print val['clf_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
