%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Short Sectioned Assignment
% LaTeX Template
% Version 1.0 (5/5/12)
%
% This template has been downloaded from:
% http://www.LaTeXTemplates.com
%
% Original author:
% Frits Wenneker (http://www.howtotex.com)
%
% License:
% CC BY-NC-SA 3.0 (http://creativecommons.org/licenses/by-nc-sa/3.0/)
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[paper=a4, fontsize=11pt]{scrartcl} % A4 paper and 10pt font size

\usepackage[T1]{fontenc} % Use 8-bit encoding that has 256 glyphs
%\usepackage{fourier} % Use the Adobe Utopia font for the document - comment this line to return to the LaTeX default
\usepackage[english]{babel} % English language/hyphenation
\usepackage{amsmath,amsfonts,amsthm} % Math packages
\usepackage{graphicx}
\usepackage{lipsum} % Used for inserting dummy 'Lorem ipsum' text into the template
\usepackage{float}
\usepackage{sectsty} % Allows customizing section commands
\allsectionsfont{\normalfont\scshape} % Make all sections centered, the default font and small caps
\usepackage{url}

\usepackage{fancyhdr} % Custom headers and footers


\usepackage{listings}
\usepackage{xcolor}

\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\lstdefinelanguage{json}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}


\lstdefinelanguage{python}{
    basicstyle=\normalfont\ttfamily,
    numbers=left,
    numberstyle=\scriptsize,
    stepnumber=1,
    numbersep=8pt,
    showstringspaces=false,
    breaklines=true,
    frame=lines,
    backgroundcolor=\color{background},
    literate=
     *{0}{{{\color{numb}0}}}{1}
      {1}{{{\color{numb}1}}}{1}
      {2}{{{\color{numb}2}}}{1}
      {3}{{{\color{numb}3}}}{1}
      {4}{{{\color{numb}4}}}{1}
      {5}{{{\color{numb}5}}}{1}
      {6}{{{\color{numb}6}}}{1}
      {7}{{{\color{numb}7}}}{1}
      {8}{{{\color{numb}8}}}{1}
      {9}{{{\color{numb}9}}}{1}
      {:}{{{\color{punct}{:}}}}{1}
      {,}{{{\color{punct}{,}}}}{1}
      {\{}{{{\color{delim}{\{}}}}{1}
      {\}}{{{\color{delim}{\}}}}}{1}
      {[}{{{\color{delim}{[}}}}{1}
      {]}{{{\color{delim}{]}}}}{1},
}



\pagestyle{fancyplain} % Makes all pages in the document conform to the custom headers and footers
\fancyhead{} % No page header - if you want one, create it in the same way as the footers below
\fancyfoot[L]{} % Empty left footer
\fancyfoot[C]{} % Empty center footer
\fancyfoot[R]{\thepage} % Page numbering for right footer
\renewcommand{\headrulewidth}{0pt} % Remove header underlines
\renewcommand{\footrulewidth}{0pt} % Remove footer underlines
\setlength{\headheight}{13.6pt} % Customize the height of the header
\usepackage{authblk}
\usepackage[margin=0.89in]{geometry}
\numberwithin{equation}{section} % Number equations within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{figure}{section} % Number figures within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)
\numberwithin{table}{section} % Number tables within sections (i.e. 1.1, 1.2, 2.1, 2.2 instead of 1, 2, 3, 4)

\setlength\parindent{0pt} % Removes all indentation from paragraphs - comment this line for an assignment with lots of text

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\newcommand{\horrule}[1]{\rule{\linewidth}{#1}} % Create horizontal rule command with 1 argument of height

\title{	
\normalfont \normalsize 
\textsc{The Ohio State University, Department of Computer Science and Engineering} \\ [25pt] % Your university, school and/or department name(s)
\horrule{0.5pt} \\[0.4cm] % Thin top horizontal rule
\huge Homework 6: Prediction of rating from Yelp review text % The assignment title
\horrule{2pt} \\[0.5cm] % Thick bottom horizontal rule
}

\author{Grover, Karan \& Arora, Pragya \& Ghai, Piyush}
\affil{\textit {\{grover.120, arora.170, ghai.8\}@osu.edu}}

\date{\normalsize\today} % Today's date or a custom date

\begin{document}
\maketitle % Print the title
\newpage
%----------------------------------------------------------------------------------------
%	PROBLEM 1
%----------------------------------------------------------------------------------------
\section{Problem Statement}
\subsection{About Yelp}
\textbf{Yelp} \cite{yelp} a famous website as well as a mobile app which publishes crowd sourced reviews about food joints and businesses. It also has a division which handles online reservations for restaurants. \textbf{Yelp Dataset Challenge}\cite{yelp_dataset_challenge} is a publicly open contest sponsored by Yelp, in which the participants are challenged to use Yelp's data in an innovative way. \\
\subsection{Our Mission}
The Yelp dataset downloaded from Yelp dataset challenge website is huge and consists of over 2.7M reviews by roughly 687k users for over 86k businesses \cite{yelp_dataset_challenge}. For this project, we chose to predict a review's rating based on the review text. The rating will be done on a scale of 1-5, where 1 stands for awful and 5 stands for excellent. We built multiple models and accessed which models would fit our use case the best. This is explained in more depth in the later sections of this report.

\subsection{About the dataset}
The Yelp Dataset consists of several files in JSON format of the data. The main files as per our use-case were the \textit{yelp\_academic\_dataset\_business.json} \& \textit{yelp\_academic\_dataset\_review.json}. The two data files were \textbf{2.13 GB} \& \textbf{73.6MB} in size respectively. The data representation in the for acadmic\_dataset\_business is as follows : \\
\begin{lstlisting}[language=json]
{
    "type": "business",
    "business_id": (encrypted business id),
    "name": (business name),
    "neighborhoods": [(hood names)],
    "full_address": (localized address),
    "city": (city),
    "state": (state),
    "latitude": latitude,
    "longitude": longitude,
    "stars": (star rating, rounded to half-stars),
    "review_count": review count,
    "categories": [(localized category names)]
    "open": True / False (corresponds to closed, not business hours),
    "hours": {
        (day_of_week): {
            "open": (HH:MM),
            "close": (HH:MM)
        },
        ...
    },
    "attributes": {
        (attribute_name): (attribute_value),
    },
}
\end{lstlisting}
The data representation in the for acadmic\_dataset\_review is as follows : \\
\begin{lstlisting}[language=json]
{   "type": "review",
    "business_id": (encrypted business id),
    "user_id": (encrypted user id),
    "stars": (star rating, rounded to half-stars),
    "text": (review text),
    "date": (date, formatted like "2012-03-14"),
    "votes": {(vote type): (count)},
}
\end{lstlisting}
The given datasets were first converted and exported into csv formats using a simple python script. The python script is a part of the \textbf{PreProcessing1.py} python file.

%% TODO Insert more sections here
\section{Exploratory Analysis of Yelp's Dataset}

\section{Program Description}
The code has been broken down into the following parts:

\begin{enumerate}
\item \textbf{Pre-Processing 1}\\
In pre-processing 1, Yelp provided JSON files were converted into the CSV format. The required CSV files were loaded as Python data-frames and then merged, filtered and stored locally for later usage.

\item \textbf{Pre-Processing 2}\\
In pre-processing 2, the review text is cleaned up, grouped and stored according to the rating of the reviews, which further gets partitioned into training and testing dataset.

\item	\textbf{Models}\\
We implemented a total of 8 models and each model has been separated into a different python file. Following are the models which were implemented and compared:
\begin{itemize}
\item \textbf{Baseline model}
\item \textbf{TFIDF model}
\item \textbf{Bag of words model}
\item \textbf{Bigram model}
\item \textbf{Trigram model}
\item \textbf{Bi and Tri-gram model}
\item \textbf{LDA Model}
\item \textbf{LDA + Sentiment layer model}
\end{itemize}
\end{enumerate}

\section{Model Description}
The following models were implemented and evaluated:

\begin{enumerate}

\item \textbf{Baseline model}\\
In the baseline model, the average rating across all reviews is assigned as the predicted rating for each review. The average rating of all reviews was found to be 3.9 which was rounded off to 4 and used as baseline prediction. This was used as a simple benchmark for all the other models we applied to this dataset.

\item \textbf{TFIDF model}\\
In TFIDF or term frequency-inverse document frequency, each review text is represented as a vector having dimension equal to the number of words in the dictionary and each dimension representing a weight of importance of the word in the review text. This TFIDF vector representations of the review corpus become the features to the classification model.

\item \textbf{Bag of words model}\\
In the bag of words or the unigram model, the review texts are converted to term frequency vectors, where each dimension represents the count of the term in the review text. The term frequency representations of the entire corpus become the features to the classification model.

\item \textbf{Bigram model}\\
In the Bigram model, the review text is broken down into bigrams - set of two words occurring consecutively in the text and the document is then represented as the term frequency vector of these bigrams. Each dimension of the term frequency vector represents the count of the bigram in the review text. 

\item \textbf{Trigam model}\\
In the Trigram model, the review text is broken down into trigrams - set of three words occurring consecutively. The term frequency vectors of these sets become the features of the review text where each dimension represents the count of the trigram in the review text.

\item Bi and Tri-gram model\\
In the Bi and Tri-gram mode, the review text is broken down into both bi and tri-grams. The term frequency vectors of these sets become the features of a review text where each dimension represents the count of the bigram or trigram in the review text.

\item \textbf{LDA model}\\
All the previous models consider all the words/bigrams/trigrams and their frequency as the training features. In the case where the corpus is huge, the dimensionality of the input features would be huge. To reduce the dimensions, we have used the Latent Dirichlet allocation (LDA) algorithm which discovers a given number of topics or themes in the corpus. Each review text is then represented as vector of probability distribution across these topics. These topic distribution vectors become the features to the classification model.
We have used the genism package in python to create the LDA model:
\begin{lstlisting}[language=python]
{
	ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics=15, id2word = dictionary)
}
\end{lstlisting}

Parameters:
\begin{itemize}
\item num\_topics:  The number of topics that should be discovered.
\item id2word: The dictionary created from the corpus
\end{itemize}

\item \textbf{LDA model + Sentiment Layer}
In this model, sentiment of the review was fed in as the feature alongside the topic distribution of the review. The sentiment of the review was extracted using the Na√Øve Bayes classifier. 
\end{enumerate}

\section{Coding Contribution}
\subsection{Data Transformation \ Pre-Processing}
Since the files were in JSON format, they were first converted to CSV format. After converting to CSV format. After converting to CSV format, the business and review data frames were joined on \textit{business\_id} for restaurant establishments. From the combined dataset, we got over 1.6M reviews for restaurants alone. The dataset now consisted of just two columns : \textit{Review Text} \& \textit{Star Rating}. \\
\begin{lstlisting}[language=python]
{
  	len(resto_review_data)
  	1630712
}
\end{lstlisting}
The length of reviews was tweaked based on our observations from Exploratory Dataset Analysis. Since a very small review might not contribute meaningfully to our models, we decided to limit the minimum characters in a review to 50, while the maximum character limit was fixed to 500 (this was kept low, because at higher ranges, the dataset was still too huge and required more computing power to run than was possible on our MacBooks).
This further reduced the number of records to a little over 900k. \\
\begin{lstlisting}[language=python]
{
  	resto_review = reduceReviewBasedOnLength(resto_review_data= resto_review_data, minReviewLen=50, maxReviewLen=500)
len(resto_review)
  	910340
}
\end{lstlisting}
\subsection{Cleaning}
Since we are dealing with real world text reviews, the data available to us will contain plenty of punctation words as well common English stopwords. We followed a standard process for text mining to further cleanse and process the review dataset. In this, we first converted all the reviews to \textbf{lowercase}. We then removed \textbf{numbers} \& \textbf{punctuations}. After this, we \textbf{tokenized} the text using the NLTK library's tokenizer. Post this, we removed the \textbf{stopwords} and we also performed \textbf{stemming} of the words. The cleaned dataset was thus used as an input to all our models trained.
\subsection{Creating Training and Testing Corpus}
We used \textbf{70-30} sampling to create a training and testing corpus from the cleaned text reviews. In order to ensure sufficient representation of all the star label values in our training corpus, we split the \textbf{original corpus on the basis of the star labels}, thus creating 5 corpora, one for each star label. The 70-30 sampling was then carried out on each of the 5 corpora and the training and test files thus created were then combined to create one big training and testing corpus. The number of reviews in training corpus for each star label is given  in Table \ref{corpus_size}.
\begin{table}[!htb]
 \centering
 \caption{Star rating distribution in the training corpora}
 \label{corpus_size}
 \begin{tabular}{l l l} 
    \noalign{\smallskip}\hline\noalign{\smallskip}
    Dataset & Count \\
    \noalign{\smallskip}\hline\noalign{\smallskip}
    Rating 1 &58739\\
    Rating 2 &47154\\
    Rating 3 &72107\\
    Rating 4 &174334\\
    Rating 5 &284902\\
    \noalign{\smallskip}\hline
  \end{tabular} 
\end{table}  
\subsection{LDA Model Development}
The LDA\cite{lda} model is present in \textbf{gensim package} in python. The inbuilt library method was not so straightforward and required a \textbf{vectorized bag of words} corpus as an input. It also required a dictionary developed from the available training corpora. The parameters that could be tweaked while developing the model were the corpora size and the total number of topics we want to extract. We chose the \textbf{total topics as 7}. In a normal vectorized corpus, the dimensionality would have been the entire size of the disctionary, which is very huge. Selecting the total topics essentially will reduce the dimensionality of our training corpora to merely 7 selected topics. The topic probability distribution dataset was used as a feature to create new training corpora which was used to train off the shelf classifiers such as \textit{MultinomialNaiveBayes, LogisticRegression, RandomForestClassifier, AdaBoostClassifier}. The performance of the models is discussed in a separate section on Model Evaluation.

\subsection{Contributions from team members}
All team members had equal contributions to this assignment. (33\% each). The key contributions are as follows : 
\begin{enumerate}
   \item Karan Grover.
   \begin{itemize}
     \item Performed the conversion of json to csv.
     \item Suggested the merger of business and reviews file into one.
     \item Performed the cleaning and pre-processing of the dataset.
   \end{itemize}
   \item Pragya Arora
   \begin{itemize}
   \item Performed the exploratory analysis of the dataset, and suggested using a limit size range of reviews.
   \item Suggested and worked on Bi-Grams, Tri Grams \& Bag of Words approach.
   \item Jointly contributed with Piyush in TF-IDF Vectorized model.
   \end{itemize}
   \item Piyush Ghai
   \begin{itemize}
   \item Suggested to keep the representation of all star labels same in the training and testing split.
   \item Suggested and worked on LDA \& LDA + Sentiment Analysis approaches for classification.
   \end{itemize}
\end{enumerate}

\section{Tools and Technology Stacks}
For this assignment, we've used a variety of tools. The coding for this assignment was done using Python. The following is an exhaustive list of modules/tools used : 
\begin{itemize}
   \item Python 2.7
   \item Pandas (For manipulating the dataframes)
   \item nltk (For corpus, dictionary, stopwords, stemming etc)
   \item NumPy (For classification model results)
   \item seaborn (For graphs)
   \item cPickle (For saving pickle files and using them later in models)
   \item iPython (The interactive python shell, which was used for development)
   \item sci-kit learn (For various classification algorithms)
   \item Gensim (For LDA model)
   \end{itemize}


\newpage
\begin{thebibliography}{}
 \bibitem{yelp}
 Yelp is an American multinational corporation headquartered in San Francisco, California. It develops, hosts and markets Yelp.com and the Yelp mobile app, which publish crowd-sourced reviews about local businesses, as well as the online reservation service Yelp Reservations and online food-delivery service Eat24. \url{https://en.wikipedia.org/wiki/Yelp}. 
 
 \bibitem{yelp_dataset_challenge}
The Yelp Dataset Challenge provides the academic community with a real-world dataset over which to apply their research. More about yelp dataset can be found on :  \url{https://www.yelp.com/dataset_challenge}. 
 
 \bibitem{nltk}
NLTK is a leading platform for building Python programs to work with human language data. It provides easy-to-use interfaces to over 50 corpora and lexical resources such as WordNet, along with a suite of text processing libraries for classification, tokenization, stemming, tagging, parsing, and semantic reasoning, wrappers for industrial-strength NLP libraries. \url{http://www.nltk.org/}. 
 
 \bibitem{lda}
In natural language processing, latent Dirichlet allocation (LDA) is a generative statistical model that allows sets of observations to be explained by unobserved groups that explain why some parts of the data are similar. For example, if observations are words collected into documents, it posits that each document is a mixture of a small number of topics and that each word's creation is attributable to one of the document's topics \url{https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation}. 
  
\end{thebibliography}


\end{document}